<img src='https://cdn.vox-cdn.com/thumbor/Z8jztI3RujKx6cNIpXjWkyOODmo=/47x217:1934x1351/1200x800/filters:focal(857x517:1183x843)/cdn.vox-cdn.com/uploads/chorus_image/image/70244595/acastro_200730_1777_ai_0001.0.jpg' width='700px' /><br/>
Language generation is the hottest thing in AI right now, with a class of systems known as “large language models” (or LLMs) being used for everything from improving Google's search engine to creating text-based fantasy games. But these programs also have serious problems, including regurgitating sexist and racist language and failing tests of logical reasoning. One big question is: can these weaknesses be improved by simply adding more data and computing power, or are we reaching the limits of this technological paradigm?
<a href='https://www.theverge.com/2021/12/8/22822199/large-language-models-ai-deepmind-scaling-gopher'> Source <a/>