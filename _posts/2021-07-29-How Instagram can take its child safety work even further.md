<img src='https://cdn.vox-cdn.com/thumbor/gOJrYh245remVqo1_7QUPHDsJEo=/0x0:2040x1360/1200x800/filters:focal(857x517:1183x843)/cdn.vox-cdn.com/uploads/chorus_image/image/69647183/acastro_190919_1777_instagram_0003.0.0.jpg' width='700px' /><br/>
In May, I wrote here that the child safety problem on tech platforms is worse than we knew. A disturbing study from the nonprofit organization Thorn found that the majority of American children were using apps years before they are supposed to be â€” and fully a quarter of them said they have had sexually explicit interactions with adults. That puts the onus on platforms to do a better job in both identifying child users of their services and to protect them from the abuse they might find there.
<a href='https://www.theverge.com/2021/7/28/22598856/instagram-child-safety-private-kids-bullying-underage-sexual-interactions'> Source <a/>